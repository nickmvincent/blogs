# Content Ecosystems and AI, some links highlights from February 2025

Sharing some recent writing, and an exciting set of articles I came across this week
that have major implications for "content ecosystems and AI".

- First, [Jacob Thebault-Spieker](https://www.linkedin.com/in/jacob-thebault-spieker-65574b112/), [Johanna Desprez](https://www.linkedin.com/in/johanna-desprez-032139125/), and I wrote ["Tipping Points for Content Ecosystems"](https://dataleverage.substack.com/p/tipping-points-for-content-ecosystems) -- a short article that argues for the need to think about impacts on "content ecosystems" in AI and society discussions.
  - In short, there's a real chance we create a "tipping point" that we can't come back in from when it comes to online knowledge production. I'm hopeful that consideration of content ecosystems is a good framing for more coalition-building in AI ethics, safety, activism, and human-centered computing. 
- Second, I was very excited to see [Shayne Longpre](https://www.shaynelongpre.com/)'s article in MIT Tech Review -- ["AI crawler wars threaten to make the web more closed for everyone"](https://www.technologyreview.com/2025/02/11/1111518/ai-crawler-wars-closed-web/), which makes a compelling case for balancing an open internet with protection for data creators.
- Third, the US copyright office released a new [report](https://www.copyright.gov/economic-research/economic-implications-of-ai/), "Identifying the Economic Implications of Artificial Intelligence for Copyright Policy". Sections 5 ("The Effects of AI Ingestion on Rightsholders’ Incentives"), 6 ("Developers’ Access to Training Data"), and 7 ("Controlling the Use of Copyrighted Materials in Training") all have major implications for content ecosystems.
- Fourth, Stella Jia and Abhishek Nagaraj shared fresh-out-of-the-lab work on ["The Impact of Pirated Data Access on LLM Performance"](https://conference.nber.org/conf_papers/f213210.pdf). The design is very cool ("to examine the causal effect of Books3 inclusion we employ an instrumental variables strategy that exploits the pattern of book publication years in the Books3 datase") and presents some of the "first empirical evidence linking access to pirated digital content, specifically
through the Books3 dataset, to enhanced performance of large language models".
- Fifth, Anthropic released an "Economic Index" with major implications for near-term augmentation and substitution, available [here](https://www.anthropic.com/news/the-anthropic-economic-index).

Some other small notes
- On the lawsuits front, it's also worth highlighting developments in the [Meta case](https://chatgptiseatingtheworld.substack.com/p/judge-chhabria-is-reviewing-metas) and a [ruling](https://www.theverge.com/news/610721/thomson-reuters-ross-intelligence-ai-copyright-infringement) in a lawsuit from Thomas Reuters (against a legal AI startup).
- In the content ecosystems post, we point to some empirical work on "ecosystem issues" with Stack Overflow, Wikipedia, and Arxiv. It was interesting to see that Obsidian is starting to deal with related issues as well, according to a [Tweet](https://x.com/kepano/status/1889362224965366214) from the founder
- There is now also some early empirical [evidence](https://www.sciencedirect.com/science/article/pii/S0167268124004591) on shifting freelancer demand from Teutloff et al.
- A new proposed bill in California could have major implications for dataset documentation, see [Tweet](https://x.com/bauerkahan/status/1887661766240514334) from Assemblymember Rebecca Bauer-Kahan
- A new OpenAI [model spec](https://openai.com/index/sharing-the-latest-model-spec/) provides a ton of insight into how the lab is handling thorny governance issues (though it doesn't mention training data)
- The Collective Intelligence Project launched [Global Dialogues](https://globaldialogues.ai/) to understand "fears, dreams, hopes, and attitudes people have about AI"
- I was excited to see Sam Altman's [blog post](https://blog.samaltman.com/three-observations) on AI discuss changes to the balance in power between labor and capital, which I expect will become a very urgent issue (there will be more connections between issues facing "content ecosystems" and labor groups)


In case you missed it:
- Last week, I wrote several newsletters about current tensions in data use and "data protection" (and impact of DeepSeek's model releases). 
  - [AI Labs Should Open Source Data Protection Technologies](https://dataleverage.substack.com/p/ai-labs-could-open-source-data-protection) 
  - [Live by the free-content-for-training sword, die by the free-content-for-training sword](https://dataleverage.substack.com/p/live-by-the-free-content-for-training)
  - I was also interviewed by [Business Insider](https://www.businessinsider.com/openai-deepseek-ai-model-distillation-training-data-copyright-karma-2025-1)