
# Some Semi-Serious Naming Proposals to Improve AI Discourse

Acknowledging the human contributions in model names and more... "Thanks, aichatbot-405b-100m."

---

Many academics are mad about the how the term AI has been used. "It’s a hype term”. “It’s for grifters”. “It’s not AI yet because there’s no symbolic reasoning”. And so on. I’m broadly sympathetic (I was excited to be quoted in this Washington Post piece last April).

In this “semi-serious” post, I’m going to propose three changes to terms used in “AI Discourse” that could improve clarity and bring attention to critical data supply chain / content ecosystems issues. I’ll keep this post pretty short.

This is “semi-serious” because I think, in some ways, the naming ship has sailed. I do not think blog posts and newsletters from early-career professors are likely to cause a widespread shift in word use frequency. Furthermore, if academics refuse to use the same language as what’s being used in public discussion (i.e., if we refuse to say “AI”), we’re giving up some of our ability to engage in science communication. But — if we don’t make some attempts to push back on terms that may cause confusion and obfuscation, we’re also complicit in the real harms that terminological choices can cause!

None of these are too catchy yet (though there’s a few I like!). But I’d like to insert them into more conversations.

#1 - Artificial Intelligence → use more specific terms whenever possible.

Why it matters: There are major differences between recommender systems, classifiers, actual robotics systems that leverage control theory, large language models, and so on. Very rarely are there policy suggestions or sweeping statements that apply to all these categories at once. While I think it’s useful to have broad coalitions with which researchers can identify, like “Responsible AI” and “AI Safety”, any time we discuss specific policy proposals we should probably try to be specific as specific. I am not even close to the first person to grump about this, but I think it’s worth repeating.

Likelihood of success: Many scholars already do this! I think this is actually very likely to succeed, but to some extent the academic community needs to continue to be annoying about this whenever possible.

Caveat: I will note that there are efforts to basically blend different types of systems together (to make a single recommender-searcher-LLM-advertising machine).

#2 - Model names with parameter counts → Model names with parameter counts and contributor counts. 

Example: Llama-3.1-405B becomes Llama-3.1-405b-50M (405B parameters and 50M individual people — a rough guess that 1% of Internet users contributed).

Even better yet would be three numbers: contributors to pre-training, post-training, and evaluation. I know this would be a stretch to adopt in almost any context, though, as it would look like: Llama-3.1-405b-50m-10k-1k (405b params, 50m people who wrote content for pre-training, 10k contractors in post-training, 1k experts who wrote special domain-specific eval set), which is quite a mouthful.

Why it matters: Current AI discourse still leans towards ignoring the massive human labour involved in pre-training, post-training, and evaluation.

Likelihood of success: While the very long version seem unlikely to catch on, I think there’s a decent chance that some models (especially if data transparency becomes more important for regulatory reasons or because of consumer demand) adapt something like this.

#3 - Synthetic Data → Refined Human Data

Example sentence: Microsoft’s new Phi-4 model has impressive capabilities for it’s size; these gains have been in part attributed to a clever approach that involves training on refined human data (outputs from a model). 

Why it matters: While the term synthetic data has a history of use in statistics and especially for privacy-preserving techniques, the term synthetic implies something has been… synthesized. Typically, something synthetic was made without access to the “natural” material. “Synthetic data” thus stands apart from synthetic materials (synthetic materials are not produced by throwing the natural material in a laundry machine and tumbling it around).

Finally, I think there’s going need to be a terminological discussion about “AI Agents”, but that product and research field is a bit too fresh and turbulent to make any confident suggestions about.