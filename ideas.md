# Ideas

A post in which I list a number of ideas. The goal is to experiment in moving more of my notes towards public, and to create some accountability in tracking which ideas I've prioritized at various points in time.

## Human stamps of approval

Every AI output maps to some set of "human stamps of approval"
- We might rephrase it as a conjecture: for a given example of a "successful AI output" (a snippet of code that solves a software engineer's problem, a reworded email that's more polite, a funny poem that makes your friends laugh), we could, given enough time and resources, produce a list of "top ten people whose stamps of approval made this possible". With even more time and resources, we might produce a list of n people that were needed for the output -- if those people never gave their stamp of approval, the output couldn't exist.
- This is a really important. It suggests, first of all, that "synthetic" data in the LLM context should also certainly just be called "processed" or "laundered" data. Say we produce synthetic data by prompting an LLM, then get very similar outputs from our "synthetically-trained LLM". We can still trace these outputs back to individual people contributing code, etc., but it's just harder now.


## Importance of Maps and Looms Metaphor

Maps: https://dataleverage.substack.com/p/ai-technologies-are-system-maps-and-you-are-a-cartographer

Looms: need to write up


## Model Naming That Emphasizes Human Contributions

https://x.com/nickmvincent/status/1829215803985801605


## Concerns with Framing of "Synthetic Data"-focused work

Core idea: "Synthetic data is not a particularly useful concept in the realm of generative AI pre-training data, if we characterize units of data using a unique set of contributor ids, which is probably a good idea in many contexts, albeit rarely practiced.

Tweet:

## Letting People Put Weights on Their Contributions to Unlock More Intelligent Models

Let me look at my old data contributions and say, this is good, this is bad

Some is inherent in institutional and community publishing practices (conference papers, upvoted posts, etc.) but tons of nuance missed

## Data Scaling Laws are Leverage Estimates

...


## Lots of value in writing out the extrems of data flow

- Opt in opt out cost curve
- Retraining frequency curve
- Preference distribution


NEVER retrain, never opt out
- perfect for historians
- compounding inequalities

Never retrain, can opt out
- people "disappear" from the timeline
- weird blips

Frequent retrain, never opt out...
Frequent retrain, can easily opt out...


## On AI Agents

Tweet: 


## All Models Are Wrong, Some Are Useful, There's Always a Model in "Prod"

all models are wrong, some are useful, but there's always a model running in prod. There's some "model" being "run" right now and every day we don't change it has some moral cost as well.

Tweet:

## Eval leverage

When models threaten the labor leverage of a group (e.g., academics who perform lit reviews become less valuable), there is some ability to "hold out" by refusing to evaluate the model. This gives a buffer before it can be deployed.

## The Moral Weight of Actuation

When you hook your model to a machine or API, there's moral weight in that choice and you take on responsibility.


Tweet: 

## Eventually all ML will become human subjects research?



## Measuring if something is really a public good (how clubby is it)?

...

## Under what conditions do corporate incentives permit FAccT work?

...

Important for students taking e.g. HCAI or Fairness class and want to practices in industry


## LLM-based "search" can be more reproducible then old school?


## More examples land value-style tax for "knowledge spaces" and "information spaces"?

Harberger tax on intellectual property

Not a new idea, e.g. radical markets

- Things in knowledge space that are static could be governed like land
- Things that are less static can be governed like digital goods
- No need to embed a poison pill in anything — either it expires or it doesn’t 
Core challenge remains 

LVT: https://en.wikipedia.org/wiki/Land_value_tax
Harberger tax, aka COST: https://en.wikipedia.org/wiki/Harberger_Tax (Common Ownership Self-assessed Tax)

## Unaddressed valuation question: how to allocate $ between people who contributed to train vs test?

If true random sample, it's equal

But if it's not a true random sample...


## Need to incentivize an append-focused lens on citation practice.

Citation lists as static artifacts don’t make (much) sense. 
If we agree more citations are better (e.g., we should have unlimited space for citations) why can't people vote to add citations or just "this is relevant" afterwords. including follow up work! People who add citations to some existing work and get social approval should some credit anyway!
Downsides: if there's no pressure along the lines of the "this is going to be archival", authors will be sloppier. I think it's worth it, though.


## Doing too much and causal inference

Doing a bunch of things at once is data poisoning against causal inference tasks